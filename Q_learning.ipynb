{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_matrix = np.genfromtxt('DataTugas3ML2019.txt', delimiter='\\t')\n",
    "reward_matrix = np.asarray(reward_matrix)\n",
    "q_table = pd.DataFrame(np.zeros((4, 225)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_learning:        \n",
    "    \n",
    "    actions = np.array(['N', 'S', 'W', 'E'])\n",
    "    list_reward = []  \n",
    "    list_step = [] \n",
    "    \n",
    "    def get_possible_actions(current_state, reward_matrix, possible_actions):\n",
    "\n",
    "        nrows, ncols = reward_matrix.shape\n",
    "        x, y = current_state    \n",
    "\n",
    "        if y==ncols-1 or reward_matrix[x, y+1]==0:\n",
    "            possible_actions = np.setdiff1d(possible_actions, 'E')\n",
    "        if y==0 or reward_matrix[x, y-1]==0:\n",
    "            possible_actions = np.setdiff1d(possible_actions, 'W')\n",
    "        if x==0 or reward_matrix[x-1, y]==0:\n",
    "            possible_actions = np.setdiff1d(possible_actions, 'N')\n",
    "        if x==nrows-1 or reward_matrix[x+1, y]==0:\n",
    "            possible_actions = np.setdiff1d(possible_actions, 'S')\n",
    "\n",
    "        return possible_actions\n",
    "    \n",
    "    def move(current_state, action):\n",
    "        next_state_x, next_state_y = current_state\n",
    "\n",
    "        if action=='N':\n",
    "            if next_state_x > 0:\n",
    "                next_state_x -=1\n",
    "        elif action=='S':\n",
    "            if next_state_x < 14:\n",
    "                next_state_x +=1\n",
    "        elif action=='W':\n",
    "            if next_state_y < 0:\n",
    "                next_state_y -=1\n",
    "        elif action=='E':\n",
    "            if next_state_y < 14:\n",
    "                next_state_y +=1\n",
    "        print(next_state_x, next_state_y)\n",
    "\n",
    "        return next_state_x, next_state_y\n",
    "    \n",
    "    def train(episode, reward_matrix, q, gamma = 0.7, alpha = 0.25):\n",
    "        for i in range(0, episode):\n",
    "            current_state = 14,0\n",
    "            reward = 0\n",
    "            step = []\n",
    "            while (reward_matrix[current_state] != 500):\n",
    "\n",
    "                new_state = current_state\n",
    "\n",
    "                directions = get_possible_actions(new_state, reward_matrix, actions)\n",
    "\n",
    "                x = random.choice(directions)\n",
    "                new_state = move(current_state, x)\n",
    "                step.append(x)\n",
    "\n",
    "                arah = np.where(actions == x)[0][0]\n",
    "                state = current_state[0]*15 + current_state[1]\n",
    "                next_state = new_state[0]*15 + new_state[1]\n",
    "\n",
    "                check_max = [q[next_state][0], q[next_state][1], q[next_state][2], q[next_state][3]]\n",
    "\n",
    "                q[state][arah] = q[state][arah] + alpha * (r[new_state] + (gamma * (max(check_max) - q[state][arah])))\n",
    "                reward = reward + r[new_state]\n",
    "\n",
    "                current_state = new_state \n",
    "\n",
    "            list_step.append(step)\n",
    "            list_reward.append(reward)\n",
    "    \n",
    "    def show(reward_matrix,q):\n",
    "        road = reward_matrix * 0\n",
    "        current_state = 14,0\n",
    "        reward = 0\n",
    "\n",
    "        road[current_state] = 1\n",
    "        step = []\n",
    "\n",
    "        while (reward_matrix[current_state] != 500): \n",
    "            possible_dir = []\n",
    "            state = current_state[0]*15 + current_state[1]\n",
    "\n",
    "            idx = [q[state][0], q[state][1], q[state][2], q[state][3]]\n",
    "            max_q = idx.index(max(idx))\n",
    "            \n",
    "\n",
    "            step.append(actions[max_q])\n",
    "\n",
    "            new_state = move(current_state, actions[max_q])\n",
    "\n",
    "            road[new_state] = 1\n",
    "\n",
    "            reward = reward + reward_matrix[new_state]\n",
    "            current_state = new_state\n",
    "        return reward, road, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = q_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.train(500,reward_matrix,q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step :  ['E', 'E', 'N', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'E', 'N', 'E', 'E', 'N', 'E', 'N', 'E', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Reward :  443.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADKlJREFUeJzt3X2sJfVdx/H3x10eZIuwlJYCiwKGkmBDhGyQ1qY2okCRsP2jf0CsQmlCGlMF06RZJLGJf7XW1IfY2BCoYiTQSMGSBlxW2saYyFrYLo9LYYvIQ5eHFgOtJMLq1z/OLLlc7929PWdm7ll+71dycubM/M6d751zP3cezsz8UlVIas9PrXYBklaH4ZcaZfilRhl+qVGGX2qU4ZcaZfilRhl+qVGGX2rU2jFndnAOqUNZN+YspQPSu09/dar3Pfn06/zgpf/JStqOGv5DWccv5ZwxZykdkLZs2THV+8467+kVt3WzX2qU4ZcaNVP4k5yf5LtJdiXZ3FdRkoY3dfiTrAG+CHwIOA24JMlpfRUmaVizrPnPAnZV1RNV9RpwM7Cpn7IkDW2W8B8PLDy0+Ew3TtIBYPCv+pJcAVwBcCiHDT07SSs0y5r/WeCEBa83dOPepKquraqNVbXxIA6ZYXaS+jRL+L8NnJLkpCQHAxcDt/dTlqShTb3ZX1V7knwS2AKsAb5cVQ/3VpmkQc20z19VdwB39FSLpBF5hp/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjZumr74Qk30zySJKHk1zZZ2GShjXL3Xv3AJ+qqu1JDgfuS7K1qh7pqTZJA5p6zV9Vu6tqezf8I2An9tUnHTB62edPciJwBrCtj58naXgzd9SZ5G3AV4GrquqVJabbUac0h2Za8yc5iEnwb6yqW5dqY0ed0nya5Wh/gOuBnVX1hf5KkjSGWdb8vwz8FvCrSXZ0jwt6qkvSwGbppfdfgPRYi6QReYaf1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSowy/1CjDLzXK8EuNMvxSo2YOf5I1Sb6T5Ot9FCRpHH2s+a9k0k+fpAPIrD32bAB+A7iun3IkjWXWNf+fAZ8G/reHWiSNaJbuui4EXqiq+/bT7ook9ya593X+e9rZSerZrN11XZTkSeBmJt12/d3iRnbUKc2nqcNfVVdX1YaqOhG4GPhGVX20t8okDcrv+aVGTd1R50JV9S3gW338LEnjcM0vNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UqFm76zoyyS1JHk2yM8l7+ypM0rBmvXvvnwP/WFUfSXIwcFgPNUkawdThT3IE8AHgMoCqeg14rZ+yJA1tls3+k4AXgb9O8p0k1yVZ11NdkgY2S/jXAmcCf1VVZwD/BWxe3MiOOqX5NEv4nwGeqapt3etbmPwzeBM76pTm0ywddT4HPJ3k1G7UOcAjvVQlaXCzHu3/XeDG7kj/E8DHZi9J0hhmCn9V7QA29lSLpBF5hp/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjDL/UKMMvNcrwS40y/FKjZu2o8/eTPJzkoSQ3JTm0r8IkDWvq8Cc5Hvg9YGNVvQdYA1zcV2GShjXrZv9a4KeTrGXSQ+/3Zy9J0hhm6bHnWeBPgKeA3cDLVXVXX4VJGtYsm/3rgU1Meus9DliX5KNLtLOjTmkOzbLZ/2vAv1fVi1X1OnAr8L7FjeyoU5pPs4T/KeDsJIclCZOOOnf2U5akoc2yz7+NSbfc24EHu591bU91SRrYrB11fgb4TE+1SBqRZ/hJjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81yvBLjTL8UqMMv9Qowy81aqabeUjaty3f37HaJSzLNb/UKMMvNcrwS43ab/iTfDnJC0keWjDuqCRbkzzePa8ftkxJfVvJmv9vgPMXjdsM3F1VpwB3d68lHUD2G/6q+mfgpUWjNwE3dMM3AB/uuS5JA5t2n/+YqtrdDT8HHNNTPZJGMvMBv6oqoJabbked0nyaNvzPJzkWoHt+YbmGdtQpzadpw387cGk3fCnwtX7KkTSWlXzVdxPwr8CpSZ5J8nHgs8CvJ3mcSVfdnx22TEl92++5/VV1yTKTzum5Fkkj8gw/qVGGX2qUl/RK+7Eal+Wed9wvTvW+x+qHK27rml9qlOGXGmX4pUYZfqlRhl9qlOGXGmX4pUYZfqlRhl9qlOGXGmX4pUYZfqlRhl9qlFf16YAyzx1fLmXaq/PG4JpfapThlxpl+KVGTdtR5+eTPJrkgSS3JTly2DIl9W3ajjq3Au+pqtOBx4Cre65L0sCm6qizqu6qqj3dy3uADQPUJmlAfezzXw7c2cPPkTSimb7nT3INsAe4cR9trgCuADiUw2aZnaQeTR3+JJcBFwLndD31LqmqrgWuBfiZHLVsO0njmir8Sc4HPg38SlW92m9JksYwbUedfwkcDmxNsiPJlwauU1LPpu2o8/oBapE0Is/wkxpl+KVGveUv6T3QLgHVcOb58trV4JpfapThlxpl+KVGGX6pUYZfapThlxpl+KVGGX6pUYZfapThlxpl+KVGGX6pUYZfatSoV/W9+/RX2bLlwLnKzqvA9Fbmml9qlOGXGmX4pUZN1VHngmmfSlJJjh6mPElDmbajTpKcAJwLPNVzTZJGMFVHnZ0/ZdJxh73wSAegqfb5k2wCnq2q+3uuR9JIfuLv+ZMcBvwBk03+lbR/o6POnz3+LX+zYOmAMc2a/+eBk4D7kzwJbAC2J3nXUo2r6tqq2lhVG9/x9jXTVyqpVz/xqriqHgTeufd19w9gY1X9oMe6JA1s2o46JR3gpu2oc+H0E3urRtJoPMNPapThlxqVqvHO0UnyIvAfy0w+Gping4bzVg/MX03Ws2+rUc/PVdU7VtJw1PDvS5J7q2rjatex17zVA/NXk/Xs27zVs5ib/VKjDL/UqHkK/7WrXcAi81YPzF9N1rNv81bPm8zNPr+kcc3Tml/SiEYPf5Lzk3w3ya4km5eYfkiSr3TTtyU5ccBaTkjyzSSPJHk4yZVLtPlgkpeT7OgefzhUPQvm+WSSB7v53bvE9CT5i24ZPZDkzAFrOXXB774jyStJrlrUZtBltNTdpJIclWRrkse75/XLvPfSrs3jSS4dsJ7PJ3m0+zxuS3LkMu/d52c7qqoa7QGsAb4HnAwcDNwPnLaoze8AX+qGLwa+MmA9xwJndsOHA48tUc8Hga+PvJyeBI7ex/QLgDuBAGcD20b8/J5j8l3yaMsI+ABwJvDQgnF/DGzuhjcDn1vifUcBT3TP67vh9QPVcy6wthv+3FL1rOSzHfMx9pr/LGBXVT1RVa8BNwObFrXZBNzQDd8CnJMkQxRTVburans3/CNgJ3D8EPPq2Sbgb2viHuDIJMeOMN9zgO9V1XInag2ilr6b1MK/kxuADy/x1vOArVX1UlX9J7CVJW5J10c9VXVXVe3pXt7D5FL3uTZ2+I8Hnl7w+hn+f9jeaNMtzJeBtw9dWLd7cQawbYnJ701yf5I7k/zC0LUwuTXaXUnu626GsthKluMQLgZuWmba2MvomKra3Q0/BxyzRJvVWk6XM9kyW8r+PtvReGsdIMnbgK8CV1XVK4smb2eymfvjJBcA/wCcMnBJ76+qZ5O8E9ia5NFubbNqkhwMXARcvcTk1VhGb6iqSjIXX1sluQbYA9y4TJO5+WzHXvM/C5yw4PWGbtySbZKsBY4AfjhUQUkOYhL8G6vq1sXTq+qVqvpxN3wHcNDQtyqvqme75xeA25jsLi20kuXYtw8B26vq+cUTVmMZAc/v3dXpnl9Yos2oyynJZcCFwG9Wt4O/2Ao+29GMHf5vA6ckOalbk1wM3L6oze3A3qOyHwG+sdyCnFV3LOF6YGdVfWGZNu/ae8whyVlMltmQ/4zWJTl87zCTA0mL+0y4Hfjt7qj/2cDLCzaBh3IJy2zyj72MOgv/Ti4FvrZEmy3AuUnWd98GnNuN612S85nczfqiqnp1mTYr+WzHM/YRRiZHqh9jctT/mm7cHzFZaACHAn8P7AL+DTh5wFrez2Qf7AFgR/e4APgE8ImuzSeBh5l8M3EP8L6Bl8/J3bzu7+a7dxktrCnAF7tl+CCT26gNWdM6JmE+YsG40ZYRk386u4HXmey3f5zJcaC7gceBfwKO6tpuBK5b8N7Lu7+lXcDHBqxnF5PjC3v/jvZ+Y3UccMe+PtvVeniGn9Qoz/CTGmX4pUYZfqlRhl9qlOGXGmX4pUYZfqlRhl9q1P8Bh3nKhlEh2DwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a11d1b710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward, road, step = q.show(reward_matrix,q_table)\n",
    "plt.imshow(road)\n",
    "plt.show\n",
    "print(\"Step : \", step)\n",
    "print(\"Reward : \", reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
